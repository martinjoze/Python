# -*- coding: utf-8 -*-
"""DML TASK1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wjqoWXflkNr6Fkv2zXPT0Ur0u9ptFq5X

**1.MLP for Binary Classification**
"""

#1.MLP for Binary Classification
use the Ionosphere binary (two-class) classification dataset to demonstrate an MLP for
binary classification.
This dataset involves predicting whether a structure is in the atmosphere or not, given radar
returns.
The dataset will be downloaded automatically using Pandas, but you can learn more about
it here.
● Ionosphere Dataset (csv).
● Ionosphere Dataset Description (csv).
You can use a LabelEncoder to encode the string labels to integer values 0 and 1. The
model will be fit on 67% of the data, and the remaining 33% will be used for evaluation, split
using the train_test_split() function.
It is good practice to use ‘relu‘ activation with a ‘he_normal‘ weight initialization. This
combination goes a long way in overcoming the problem of vanishing gradients when
training deep neural network models.
The model predicts the probability of class 1 and uses the sigmoid activation function. The
model is optimized using the adam version of stochastic gradient descent and seeks to
minimize the cross-entropy loss

!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv

# mlp for binary classification
from pandas import read_csv
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
# load the dataset
path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'
df = read_csv(path, header=None)
# split into input and output columns
X, y = df.values[:, :-1], df.values[:, -1]
# ensure all data are floating point values
X = X.astype('float32')
# encode strings to integer
y = LabelEncoder().fit_transform(y)
# split into train and test datasets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)
# determine the number of input features
n_features = X_train.shape[1]
# define model
model = Sequential()
model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))
model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))
model.add(Dense(1, activation='sigmoid'))
# compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
# fit the model
model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)
# evaluate the model
loss, acc = model.evaluate(X_test, y_test, verbose=0)
print('Test Accuracy: %.3f' % acc)
# make a prediction
row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,
       -0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]
yhat = model.predict([row])
print('Predicted: %.3f' % yhat)

"""**2.MLP for Multiclass Classification**"""

#2.MLP for Multiclass Classification
We will use the Iris flowers multiclass classification dataset to demonstrate an MLP for
multiclass classification.
This problem involves predicting the species of iris flower given measures of the flower.
The dataset will be downloaded automatically using Pandas, but you can learn more about
it here.
● Iris Dataset (csv).
● Iris Dataset Description (csv).
Given that it is a multiclass classification, the model must have one node for each class in
the output layer and use the softmax activation function. The loss function is the
‘sparse_categorical_crossentropy‘, which is appropriate for integer encoded class labels
(e.g., 0 for one class, 1 for the next class, etc.)

!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv

# mlp for multiclass classification
from numpy import argmax
from pandas import read_csv
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
# load the dataset
path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv'
df = read_csv(path, header=None)
# split into input and output columns
X, y = df.values[:, :-1], df.values[:, -1]
# ensure all data are floating point values
X = X.astype('float32')
# encode strings to integer
y = LabelEncoder().fit_transform(y)
# split into train and test datasets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)
# determine the number of input features
n_features = X_train.shape[1]
# define model
model = Sequential()
model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))
model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))
model.add(Dense(3, activation='softmax'))
# compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
# fit the model
model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)
# evaluate the model
loss, acc = model.evaluate(X_test, y_test, verbose=0)
print('Test Accuracy: %.3f' % acc)
# make a prediction
row = [5.1,3.5,1.4,0.2]
yhat = model.predict([row])
print('Predicted: %s (class=%d)' % (yhat, argmax(yhat)))

"""**3.MLP for Regression**"""

#3.MLP for Regression
Use the Boston housing regression dataset to demonstrate an MLP for regression
predictive modeling.
This problem involves predicting house value based on the properties of the house and
neighborhood.
The dataset will be downloaded automatically using Pandas, but you can learn more about
it here.
● Boston Housing Dataset (csv).
● Boston Housing Dataset Description (csv).
This is a regression problem that involves predicting a single numerical value. As such, the
output layer has a single node and uses the default or linear activation function (no
activation function). The mean squared error (mse) loss is minimized when fitting the model.

!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv

# mlp for regression
from numpy import sqrt
from pandas import read_csv
from sklearn.model_selection import train_test_split
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
# load the dataset
path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'
df = read_csv(path, header=None)
# split into input and output columns
X, y = df.values[:, :-1], df.values[:, -1]
# split into train and test datasets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)
# determine the number of input features
n_features = X_train.shape[1]
# define model
model = Sequential()
model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))
model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))
model.add(Dense(1))
# compile the model
model.compile(optimizer='adam', loss='mse')
# fit the model
model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)
# evaluate the model
error = model.evaluate(X_test, y_test, verbose=0)
print('MSE: %.3f, RMSE: %.3f' % (error, sqrt(error)))
# make a prediction
row = [0.00632,18.00,2.310,0,0.5380,6.5750,65.20,4.0900,1,296.0,15.30,396.90,4.98]
yhat = model.predict([row])
print('Predicted: %.3f' % yhat)

"""**#4.Deep Learning CNN for Fashion-MNIST**"""

#4.Deep Learning CNN for Fashion-MNIST
Clothing Classification
The Fashion-MNIST clothing classification problem is a new standard dataset used in
computer vision and deep learning.
Dataset : https://github.com/zalandoresearch/fashion-mnist

!wget https://github.com/zalandoresearch/fashion-mnist

from tensorflow.keras.datasets import fashion_mnist
import matplotlib.pyplot as plt
(train_images,train_labels),(test_images,test_labels)=fashion_mnist.load_data()
print("Training images shape:",train_images.shape)
print("Training labels shape:",train_labels.shape)
print("Test images shape:",test_images.shape)
print("Test labels shape:",test_labels.shape)
class_names=['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag',
             'Ankle boot']
plt.figure()
plt.imshow(train_images[0],cmap='gray')
plt.colorbar()
plt.grid(False)
plt.title(f"Class:{class_names[train_labels[0]]}")
plt.show()
